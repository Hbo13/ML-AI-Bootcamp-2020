{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hasnaa A2.3.3 Google_ai_api - students' sheet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWerB5_2gRaH"
      },
      "source": [
        "# Google's Natural Language service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqEceeQG_K1F"
      },
      "source": [
        "## Google's AI and machine learning products\n",
        "[Google's AI and machine learning products](https://cloud.google.com/products/ai/?tab=tab2)\n",
        "+ **AI Hub**, hosted repository of plug-and-play AI components, encourages experimentation and collaboration within an organization.\n",
        "+ **AI building blocks** make it easy for developers to add some AI to their applications.\n",
        "+ **AI Platform**, code-based data science development environment, lets ML developers and data scientists quickly take projects from ideation to deployment.\n",
        "\n",
        "In this section, we are interested in the [\"AI building blocks\"](https://cloud.google.com/products/ai/building-blocks/), which consists of 4 categories:\n",
        "+ Sight: Vision, Video\n",
        "+ Language: Translation, Natural Language\n",
        "+ Conversation: dialogflow, Cloud Text-to-Speech API,Cloud Speech-to-Text API\n",
        "+ Structured data: AutoML Tables, Recommendations AI, Cloud Inference API\n",
        "\n",
        "More precisely, we will discover the **Natural Language** service (API and autoML) in the category \"Language\", and some **Vision API** (object detection).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXFHsJ9gJe1U"
      },
      "source": [
        "## Natural Language\n",
        "\n",
        "**Natural Language** service uses Google machine learning to reveal the structure and meaning of text. We can extract information about people, places, and events, and better understand social media sentiment and customer conversations. **Natural Language** enables us to analyze text and also integrate it with our document storage on Google Cloud Storage. \n",
        "\n",
        "In the service, Google introduces AutoML Natural Language and Natural Language API, and we are interested in the later one.\n",
        "\n",
        "**Task 1:** Try the demo of the [**Natural Language** ](https://cloud.google.com/natural-language/)service and observe the results. What do you think about the quality of the analysis?\n",
        "\n",
        "When we try out some text, the API demo produces some analyses: \n",
        "+ **Entity Analysis** provides information about entities in the text, which generally refer to named \"things\" such as famous individuals, landmarks, common objects, etc. There are proper nouns (specific people, place, organization, etc.) and common nouns. A good general practice to follow is that if something is a noun, it qualifies as an \"entity.\" For each entity, we have:\n",
        "  + its `type` (location, person, other, etc.) \n",
        "  + a `saliance` score, indicating its relevance to the text. Its value is between 0 and 1, where 1 means highly important.\n",
        "  + some `metadata` which contains source information about the entity's knowledge repository\n",
        "  + `mentions` indicating offset positions within the text where it is mentioned. \n",
        "+ **Sentiment analysis** attempts to determine the attitudes (positive or negative) expressed within: the entire document, each paragraph, and each entity. Sentiment is represented by `score` and `magnitude` values. `Score` ranges from -1 (very negative) to +1 (very positive). `Magnitude` indicates the overall strength of emotion (both positive and negative) within the given text. Unlike `score`, `magnitude` is not normalized. Therefore, longer text may have greater `magnitude`.\n",
        "+ **Syntactic analysis** provides a powerful set of tools for analyzing and parsing text. The text is divided into sentences, tokens (usually a word); tokens' parts of speech and dependencies are determined; etc.\n",
        "+ **Content Classification** returns a list of content categories that apply to the text.\n",
        "  \n",
        "\n",
        "  **Guide:**\n",
        "+ Create a service account.\n",
        "+ [Download a private key as JSON](https://console.cloud.google.com/apis/credentials/serviceaccountkey). Upload the key (if using Colab). (another [guide](https://cloud.google.com/iam/docs/creating-managing-service-account-keys#iam-service-account-keys-create-console))\n",
        "+ Passing the key directly, like\n",
        "`client = language.LanguageServiceClient(\"/content/My First Project-f1aac12d8d07.json\")`, [won't work](https://github.com/googleapis/google-cloud-python/issues/5349).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQpbfTudgDxS"
      },
      "source": [
        "## First text analysis\n",
        "\n",
        "From [overview page](https://cloud.google.com/natural-language/) of Natural Language, we can select \"Get started\" then \"Natural Language API\" to jump to the [documentation site](https://cloud.google.com/natural-language/docs/quickstarts).\n",
        "\n",
        "**Task 2:** Use Cloud Natural Language API (provided by Google Cloud Client Libraries in Python) to analyze your first text. You may want to use this [Quickstart](https://cloud.google.com/natural-language/docs/quickstart-client-libraries), the documentation, etc. To use this service, you will need to create or choose a project with a bank accout. You may also need to create a private key (JSON).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO2CazR1bTB-",
        "outputId": "38a31239-9b7d-4de0-966d-c1c153f23f07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pIRXGuWcRBO",
        "outputId": "bd299a9a-f275-4e64-a01e-50c7bf976e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "!pip install --upgrade google-cloud-language"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google-cloud-language\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/b8/965a97ba60287910d342623da1da615254bded3e0965728cf7fc6339b7c8/google_cloud_language-1.3.0-py2.py3-none-any.whl (83kB)\n",
            "\r\u001b[K     |████                            | 10kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-language) (1.16.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (45.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (1.51.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (1.27.1)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-language) (0.4.8)\n",
            "Installing collected packages: google-cloud-language\n",
            "  Found existing installation: google-cloud-language 1.2.0\n",
            "    Uninstalling google-cloud-language-1.2.0:\n",
            "      Successfully uninstalled google-cloud-language-1.2.0\n",
            "Successfully installed google-cloud-language-1.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_0bQJKR3eoe",
        "outputId": "ff9ddf39-f23a-4091-869c-b29e6dae45f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Imports the Google Cloud client library\n",
        "from google.cloud import language\n",
        "from google.cloud.language import enums\n",
        "from google.cloud.language import types\n",
        "import json\n",
        "\n",
        "# Instantiates a client\n",
        "from google.oauth2 import service_account\n",
        "credentials = service_account.Credentials.from_service_account_file(\"/content/drive/My Drive/My_First_Project-599c9a871c2b.json\")\n",
        "\n",
        "client = language.LanguageServiceClient(credentials=credentials)\n",
        "\n",
        "# The text to analyze\n",
        "text = u'Hello, world!'\n",
        "document = types.Document(\n",
        "    content=text,\n",
        "    type=enums.Document.Type.PLAIN_TEXT)\n",
        "\n",
        "# Detects the sentiment of the text\n",
        "sentiment = client.analyze_sentiment(document=document).document_sentiment\n",
        "\n",
        "print('Text: {}'.format(text))\n",
        "print('Sentiment: {}, {}'.format(sentiment.score, sentiment.magnitude))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text: Hello, world!\n",
            "Sentiment: 0.30000001192092896, 0.30000001192092896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gshs-cDQGvwA"
      },
      "source": [
        "##Sentiment analysis\n",
        "\n",
        "**Task 3:** \n",
        "+ Download this [data](https://www.kaggle.com/crowdflower/twitter-airline-sentiment) for sentiment analysis from Kaggle. Read the data description for more understanding.\n",
        "\n",
        "+ Use the model of Google to analyse 10 first tweets. Compare the results the given sentiments, are they different? what is your opinion?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiCY4tLZ3mE8"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/My Drive/Toptal/twitter-airline-sentiment.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XASB9giiFRu"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/Tweets.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcfBhizeiZ1V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "e240228d-1429-4819-ceff-a6f85ff96655"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV5_3NNtiuZu"
      },
      "source": [
        "scores = []\n",
        "magnitudes = []\n",
        "for text in data['text'][:10]:\n",
        "  document = types.Document(\n",
        "    content=text,\n",
        "    type=enums.Document.Type.PLAIN_TEXT)\n",
        "  sentiment = client.analyze_sentiment(document=document).document_sentiment\n",
        "  scores.append(sentiment.score)\n",
        "  magnitudes.append(sentiment.magnitude)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygqXNNq1iwSu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "c3b4aa85-5d21-4863-8528-c8ac96c79fa5"
      },
      "source": [
        "pd.DataFrame({'given_sentiment':data['airline_sentiment'][:10],\n",
        "             'given_confidence':data['airline_sentiment_confidence'][:10],\n",
        "             'predicted_score':pd.Series(scores)})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>given_sentiment</th>\n",
              "      <th>given_confidence</th>\n",
              "      <th>predicted_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>-0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>-0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>-0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>positive</td>\n",
              "      <td>0.6745</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6340</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>positive</td>\n",
              "      <td>0.6559</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>positive</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  given_sentiment  given_confidence  predicted_score\n",
              "0         neutral            1.0000              0.0\n",
              "1        positive            0.3486             -0.2\n",
              "2         neutral            0.6837              0.0\n",
              "3        negative            1.0000             -0.9\n",
              "4        negative            1.0000             -0.8\n",
              "5        negative            1.0000              0.1\n",
              "6        positive            0.6745              0.2\n",
              "7         neutral            0.6340              0.2\n",
              "8        positive            0.6559              0.5\n",
              "9        positive            1.0000              0.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2PYWbTgpl4k"
      },
      "source": [
        "## Content classification\n",
        "\n",
        "**Task 4:** \n",
        "1. Find and download a dataset for text classification. \n",
        "1. Choose several texts, then apply classification API. Have you obtained good results?\n",
        "1. Can you use the classification API for a specific text classfication problem?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crw4QkAJ3siH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d7c001a-2bed-4199-bc91-4ca79587593f"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "url = 'http://qwone.com/~jason/20Newsgroups/20news-19997.tar.gz'\n",
        "urllib.request.urlretrieve(url, '/content/20news-19997.tar.gz')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/20news-19997.tar.gz', <http.client.HTTPMessage at 0x7f3ab4ae6c50>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FfakYnqjYQf"
      },
      "source": [
        "import tarfile\n",
        "tar = tarfile.open('/content/20news-19997.tar.gz')\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_Ua04D_kQtD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "4bf3b7cf-826e-452f-f5a0-a8d884ca9f61"
      },
      "source": [
        "import six\n",
        "from google.cloud import language\n",
        "from google.cloud.language import enums\n",
        "from google.cloud.language import types\n",
        "\n",
        "client = language.LanguageServiceClient(credentials=credentials)\n",
        "\n",
        "import glob\n",
        "texts_paths = glob.glob('/content/20_newsgroups/comp.graphics/*')[:5]\n",
        "print(texts_paths)\n",
        "\n",
        "for i in range(len(texts_paths)):\n",
        "  # method 1\n",
        "  days_file = open(texts_paths[i],'r')\n",
        "  text = days_file.read()\n",
        "\n",
        "  document = types.Document(\n",
        "      content=text.encode('utf-8'),\n",
        "      type=enums.Document.Type.PLAIN_TEXT)\n",
        "\n",
        "  categories = client.classify_text(document).categories\n",
        "  \n",
        "  print(u'=' * 80)\n",
        "  print('Document:', texts_paths[i])\n",
        "  for category in categories:\n",
        "      print(u'=' * 20)\n",
        "      print(u'{:<16}: {}'.format('name', category.name))\n",
        "      print(u'{:<16}: {}'.format('confidence', category.confidence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/20_newsgroups/comp.graphics/38918', '/content/20_newsgroups/comp.graphics/38442', '/content/20_newsgroups/comp.graphics/38971', '/content/20_newsgroups/comp.graphics/38584', '/content/20_newsgroups/comp.graphics/38543']\n",
            "================================================================================\n",
            "Document: /content/20_newsgroups/comp.graphics/38918\n",
            "====================\n",
            "name            : /Jobs & Education/Education\n",
            "confidence      : 0.5199999809265137\n",
            "================================================================================\n",
            "Document: /content/20_newsgroups/comp.graphics/38442\n",
            "====================\n",
            "name            : /Computers & Electronics\n",
            "confidence      : 0.7599999904632568\n",
            "====================\n",
            "name            : /Science/Computer Science\n",
            "confidence      : 0.6800000071525574\n",
            "================================================================================\n",
            "Document: /content/20_newsgroups/comp.graphics/38971\n",
            "====================\n",
            "name            : /Arts & Entertainment\n",
            "confidence      : 0.800000011920929\n",
            "================================================================================\n",
            "Document: /content/20_newsgroups/comp.graphics/38584\n",
            "================================================================================\n",
            "Document: /content/20_newsgroups/comp.graphics/38543\n",
            "====================\n",
            "name            : /Computers & Electronics/Software\n",
            "confidence      : 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuvSiRgq0lXY"
      },
      "source": [
        "## AutoML Natural Language\n",
        "\n",
        "**AutoML** services allow us to adapt Google models to our problems.\n",
        "\n",
        "**Task 5:** \n",
        "+ Build a custom classification model using the Cloud AutoML Natural Language. You might use this [Quickstart](https://cloud.google.com/natural-language/automl/docs/quickstart). \n",
        "+ When the training is finished, see if you get good test performance. \n",
        "+ Apply the model to classify the text below using Python. Print the labels and the scores.\n",
        "\n",
        "**Notice:** \n",
        "+ You shouldn't use lots of data because uploading and training is quite time-consuming. Training with a data of 1000 first examples of the data in the Quickstart may take 4 hours (the training time is not proportional to the number of examples). \n",
        "+ Proceed the next tasks while the model is trained on the cloud.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An2UgyKQsYBv"
      },
      "source": [
        "# text to test\n",
        "content = 'I measured my weight and found to be 1 pound lesser than the earlier day'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwNvJxa13yxm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "178fa3b3-b66b-416c-d013-cb0ed31d78d5"
      },
      "source": [
        "!pip install google-cloud-automl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google-cloud-automl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/83/13ec95d3689b53586f72f5e81c253eb11e43ef5219ba55b7d7495ea86324/google_cloud_automl-0.10.0-py2.py3-none-any.whl (372kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-automl) (1.16.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (2.21.0)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (45.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (1.12.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (3.10.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (1.51.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (1.7.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (1.27.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (2019.11.28)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl) (0.4.8)\n",
            "Installing collected packages: google-cloud-automl\n",
            "Successfully installed google-cloud-automl-0.10.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2HBcqSokx5E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "9fb3f663-99e8-4386-c04f-a90e270357f0"
      },
      "source": [
        "import sys\n",
        "\n",
        "from google.cloud import automl_v1beta1\n",
        "from google.cloud.automl_v1beta1.proto import service_pb2\n",
        "\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "credentials = service_account.Credentials.from_service_account_file('/content/drive/My Drive/My_First_Project-599c9a871c2b.json')\n",
        "\n",
        "def get_prediction(content, project_id, model_id, credentials):\n",
        "  prediction_client = automl_v1beta1.PredictionServiceClient(credentials=credentials)\n",
        "\n",
        "  name = 'projects/{}/locations/us-central1/models/{}'.format(project_id, model_id)\n",
        "  payload = {'text_snippet': {'content': content, 'mime_type': 'text/plain' }}\n",
        "  params = {}\n",
        "  request = prediction_client.predict(name, payload, params)\n",
        "  return request  # waits till request is returned\n",
        "\n",
        "project_id = 'vocal-unfolding-268915'\n",
        "model_id = 'TCN1454844679040226528'\n",
        "\n",
        "pred=get_prediction(content, project_id,  model_id, credentials)\n",
        "\n",
        "for i in pred.payload:\n",
        "  print('Name:',i.display_name+'; score:', i.classification.score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFound",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    825\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m--> 826\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"The model is either not found or not supported for prediction yet.\"\n\tdebug_error_string = \"{\"created\":\"@1582555033.649615148\",\"description\":\"Error received from peer ipv4:74.125.134.95:443\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"The model is either not found or not supported for prediction yet.\",\"grpc_status\":5}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-851af4d6c129>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'TCN1454844679040226528'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_id\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-851af4d6c129>\u001b[0m in \u001b[0;36mget_prediction\u001b[0;34m(content, project_id, model_id, credentials)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text_snippet'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mime_type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'text/plain'\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m  \u001b[0;31m# waits till request is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/cloud/automl_v1beta1/gapic/prediction_service_client.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, name, payload, params, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         return self._inner_api_calls[\"predict\"](\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         )\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             )\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;34m\"\"\"Wrapped function that adds timeout.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mNotFound\u001b[0m: 404 The model is either not found or not supported for prediction yet."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X36g00XlgDpx"
      },
      "source": [
        "## Entity Analysis\n",
        "\n",
        "**Task 6:** Use the Google API to find the entities in the text below. For each entity, print its name, type, salience and wikipedia url. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te9krt08SUqz"
      },
      "source": [
        "# Text to analyse\n",
        "text = 'The name machine learning was coined in 1959 by \\\n",
        "Arthur Samuel. Tom M. Mitchell provided a widely quoted, \\\n",
        "more formal definition of the algorithms studied in the machine \\\n",
        "learning field: \"A computer program is said to learn from experience \\\n",
        "E with respect to some class of tasks T and performance measure P if \\\n",
        "its performance at tasks in T, as measured by P, improves with experience E.\"'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZl4NLlT31kE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd0414f2-0f64-43f5-ff76-052f9df3313f"
      },
      "source": [
        "import six\n",
        "from google.cloud import language\n",
        "from google.cloud.language import enums\n",
        "from google.cloud.language import types\n",
        "\n",
        "client = language.LanguageServiceClient(credentials=credentials)\n",
        "\n",
        "if isinstance(text, six.binary_type):\n",
        "    text = text.decode('utf-8')\n",
        "\n",
        "# Instantiates a plain text document.\n",
        "document = types.Document(\n",
        "    content=text,\n",
        "    type=enums.Document.Type.PLAIN_TEXT)\n",
        "\n",
        "# Detects entities in the document. You can also analyze HTML with:\n",
        "#   document.type == enums.Document.Type.HTML\n",
        "entities = client.analyze_entities(document).entities\n",
        "\n",
        "for entity in entities:\n",
        "    entity_type = enums.Entity.Type(entity.type)\n",
        "    print('=' * 20)\n",
        "    print(u'{:<16}: {}'.format('name', entity.name))\n",
        "    print(u'{:<16}: {}'.format('type', entity_type.name))\n",
        "    print(u'{:<16}: {}'.format('salience', entity.salience))\n",
        "    print(u'{:<16}: {}'.format('wikipedia_url',\n",
        "          entity.metadata.get('wikipedia_url', '-')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================\n",
            "name            : name machine learning\n",
            "type            : OTHER\n",
            "salience        : 0.3405567407608032\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : T\n",
            "type            : OTHER\n",
            "salience        : 0.09719357639551163\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : performance measure P\n",
            "type            : OTHER\n",
            "salience        : 0.09703781455755234\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : Arthur Samuel\n",
            "type            : PERSON\n",
            "salience        : 0.07251947373151779\n",
            "wikipedia_url   : https://en.wikipedia.org/wiki/Arthur_Samuel\n",
            "====================\n",
            "name            : experience\n",
            "type            : OTHER\n",
            "salience        : 0.04233669862151146\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : machine learning field\n",
            "type            : LOCATION\n",
            "salience        : 0.040550436824560165\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : computer program\n",
            "type            : OTHER\n",
            "salience        : 0.040550436824560165\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : algorithms\n",
            "type            : OTHER\n",
            "salience        : 0.040059760212898254\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : respect\n",
            "type            : OTHER\n",
            "salience        : 0.03723657876253128\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : Tom M. Mitchell\n",
            "type            : PERSON\n",
            "salience        : 0.03514755889773369\n",
            "wikipedia_url   : https://en.wikipedia.org/wiki/Tom_M._Mitchell\n",
            "====================\n",
            "name            : tasks\n",
            "type            : OTHER\n",
            "salience        : 0.031988319009542465\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : performance\n",
            "type            : OTHER\n",
            "salience        : 0.031988319009542465\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : definition\n",
            "type            : OTHER\n",
            "salience        : 0.030634747818112373\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : experience E\n",
            "type            : OTHER\n",
            "salience        : 0.022442029789090157\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : tasks\n",
            "type            : OTHER\n",
            "salience        : 0.014087430201470852\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : P\n",
            "type            : PERSON\n",
            "salience        : 0.013292049989104271\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : class\n",
            "type            : OTHER\n",
            "salience        : 0.01237801555544138\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : 1959\n",
            "type            : DATE\n",
            "salience        : 0.0\n",
            "wikipedia_url   : -\n",
            "====================\n",
            "name            : 1959\n",
            "type            : NUMBER\n",
            "salience        : 0.0\n",
            "wikipedia_url   : -\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-yEfwDu5Ta3"
      },
      "source": [
        "## Google Vision API\n",
        "\n",
        "[Cloud Vision API](https://cloud.google.com/vision/) allows developers to easily integrate vision detection features within applications, including image labeling, face and landmark detection, optical character recognition (OCR), and tagging of explicit content.\n",
        "\n",
        "#### List of all Cloud Vision API features:\n",
        "1. Face detection\n",
        "1. Landmark detection\n",
        "1. Logo detection\n",
        "1. Label detection (Provides generalized labels for an image)\n",
        "1. Text detection\n",
        "1. Document text detection (dense text / handwriting)\n",
        "1. Image properties\n",
        "1. Object localization\n",
        "1. Crop hint detection\n",
        "1. Web entities and pages\n",
        "\n",
        "[Try it!](https://cloud.google.com/vision/docs/drag-and-drop)\n",
        "\n",
        "**Task 7:** Detect objects in the [image](https://upload.wikimedia.org/wikipedia/commons/1/14/Animal_diversity.png) below using Google API and comment the result.\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/1/14/Animal_diversity.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahl3ntG7qVhY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "5c7ffbf5-3e13-4aa2-d51b-94ccca7c216b"
      },
      "source": [
        "!pip install --upgrade google-cloud-vision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google-cloud-vision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/23/6d5a728333ce568fb484d0d7edd0b7c04b16cf6325af31d957eb51ed077d/google_cloud_vision-0.42.0-py2.py3-none-any.whl (435kB)\n",
            "\u001b[K     |████████████████████████████████| 440kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-vision) (1.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.51.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (45.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.27.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (0.4.8)\n",
            "Installing collected packages: google-cloud-vision\n",
            "Successfully installed google-cloud-vision-0.42.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoJ3PoV0qYbR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1422efae-1fe5-404e-e8ee-def20094f7ba"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "url = \"https://upload.wikimedia.org/wikipedia/commons/1/14/Animal_diversity.png\"\n",
        "urllib.request.urlretrieve(url, '/content/animals.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/animals.png', <http.client.HTTPMessage at 0x7f053f7017f0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB4GzQg1q1en"
      },
      "source": [
        "import io\n",
        "import os\n",
        "\n",
        "# Imports the Google Cloud client library\n",
        "from google.cloud import vision\n",
        "from google.cloud.vision import types\n",
        "\n",
        "client = vision.ImageAnnotatorClient(credentials=credentials)\n",
        "\n",
        "file_name = '/content/animals.png' # Loads the image into memory\n",
        "with io.open(file_name, 'rb') as image_file:\n",
        "    content = image_file.read()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW6woMA7rGCn"
      },
      "source": [
        "image = types.Image(content=content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkXxEYA8rHdZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "29f1966f-c012-4dd3-d6c0-86c09b03116e"
      },
      "source": [
        "print('='*40)\n",
        "print('Label detection:')\n",
        "response = client.label_detection(image=image)\n",
        "labels = response.label_annotations\n",
        "\n",
        "print('Labels:')\n",
        "for label in labels:\n",
        "    print(label.description)\n",
        "\n",
        "# Multiple oject detection\n",
        "print('='*40)\n",
        "print('Multiple oject detection:')\n",
        "path =  '/content/animals.png'\n",
        "with open(path, 'rb') as image_file:\n",
        "    content = image_file.read()\n",
        "image = vision.types.Image(content=content)\n",
        "\n",
        "objects = client.object_localization(\n",
        "    image=image).localized_object_annotations\n",
        "\n",
        "print('Number of objects found: {}'.format(len(objects)))\n",
        "for object_ in objects:\n",
        "    print('\\n{} (confidence: {})'.format(object_.name, object_.score))\n",
        "    print('Normalized bounding polygon vertices: ')\n",
        "    for vertex in object_.bounding_poly.normalized_vertices:\n",
        "        print(' - ({}, {})'.format(vertex.x, vertex.y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Label detection:\n",
            "Labels:\n",
            "Bengal tiger\n",
            "Wildlife\n",
            "Organism\n",
            "Tiger\n",
            "Graphic design\n",
            "Collage\n",
            "Adaptation\n",
            "Illustration\n",
            "Photography\n",
            "Font\n",
            "========================================\n",
            "Multiple oject detection:\n",
            "Number of objects found: 10\n",
            "\n",
            "Tiger (confidence: 0.8511397838592529)\n",
            "Normalized bounding polygon vertices: \n",
            " - (0.3848460614681244, 0.33132120966911316)\n",
            " - (0.6488093733787537, 0.33132120966911316)\n",
            " - (0.6488093733787537, 0.49733075499534607)\n",
            " - (0.3848460614681244, 0.49733075499534607)\n",
            "\n",
            "Animal (confidence: 0.8192296028137207)\n",
            "Normalized bounding polygon vertices: \n",
            " - (0.6680896878242493, 0.5144973397254944)\n",
            " - (0.9220726490020752, 0.5144973397254944)\n",
            " - (0.9220726490020752, 0.6526311039924622)\n",
            " - (0.6680896878242493, 0.6526311039924622)\n",
            "\n",
            "Animal (confidence: 0.8099767565727234)\n",
            "Normalized bounding polygon vertices: \n",
            " - (0.6845981478691101, 0.33075228333473206)\n",
            " - (0.9412550926208496, 0.33075228333473206)\n",
            " - (0.9412550926208496, 0.5037023425102234)\n",
            " - (0.6845981478691101, 0.5037023425102234)\n",
            "\n",
            "Animal (confidence: 0.7711507678031921)\n",
            "Normalized bounding polygon vertices: \n",
            " - (0.010822768323123455, 0.6701207160949707)\n",
            " - (0.32849761843681335, 0.6701207160949707)\n",
            " - (0.32849761843681335, 0.8334006667137146)\n",
            " - (0.010822768323123455, 0.8334006667137146)\n",
            "\n",
            "Insect (confidence: 0.7640390396118164)\n",
            "Normalized bounding polygon vertices: \n",
            " - (0.3549189567565918, 0.17213521897792816)\n",
            " - (0.6515346169471741, 0.17213521897792816)\n",
            " - (0.6515346169471741, 0.2961820065975189)\n",
            " - (0.3549189567565918, 0.2961820065975189)\n",
            "\n",
            "Insect (confidence: 0.7335182428359985)\n",
            "Normalized bounding polygon vertices: \n",
            " - (0.0031276491936296225, 0.8549602627754211)\n",
            " - (0.3324064612388611, 0.8549602627754211)\n",
            " - (0.3324064612388611, 0.9973958134651184)\n",
            " - (0.0031276491936296225, 0.9973958134651184)\n",
            "\n",
            "Insect (confidence: 0.7108140587806702)\n",
            "Normalized bounding polygon vertices: \n",
            " - (0.6862064003944397, 0.1810692995786667)\n",
            " - (0.9886839985847473, 0.1810692995786667)\n",
            " - (0.9886839985847473, 0.3009568154811859)\n",
            " - (0.6862064003944397, 0.3009568154811859)\n",
            "\n",
            "Animal (confidence: 0.7011115550994873)\n",
            "Normalized bounding polygon vertices: \n",
            " - (0.6878414750099182, 0.011247280985116959)\n",
            " - (0.9818795323371887, 0.011247280985116959)\n",
            " - (0.9818795323371887, 0.1427355855703354)\n",
            " - (0.6878414750099182, 0.1427355855703354)\n",
            "\n",
            "Animal (confidence: 0.6947831511497498)\n",
            "Normalized bounding polygon vertices: \n",
            " - (0.6764647960662842, 0.8375096917152405)\n",
            " - (0.9547638297080994, 0.8375096917152405)\n",
            " - (0.9547638297080994, 0.9941655993461609)\n",
            " - (0.6764647960662842, 0.9941655993461609)\n",
            "\n",
            "Animal (confidence: 0.6918931007385254)\n",
            "Normalized bounding polygon vertices: \n",
            " - (0.6724879145622253, 0.6945397257804871)\n",
            " - (0.9453825354576111, 0.6945397257804871)\n",
            " - (0.9453825354576111, 0.8244401812553406)\n",
            " - (0.6724879145622253, 0.8244401812553406)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "572DTxkVdk0h"
      },
      "source": [
        "## Extra tasks\n",
        "+ Build a model using \"AutoML Vision\".\n",
        "+ Try similar tasks with other services.\n",
        "+ Use other programming languages."
      ]
    }
  ]
}